{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1639b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the saved model and scaler...\n",
      "Model and scaler loaded successfully.\n",
      "Creating prediction grid...\n",
      "Engineering features for the grid...\n",
      "Scaling grid features...\n",
      "Predicting foraging probability on the grid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "a:\\SHARKS\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction complete.\n",
      "Exporting results to hotspots.geojson...\n",
      "\n",
      "✅ Phase 3 Complete! Your final, high-performance 'hotspots.geojson' is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import geojson\n",
    "\n",
    "# 1. Load your best model and the scaler\n",
    "print(\"Loading the saved model and scaler...\")\n",
    "model = joblib.load('best_shark_model_lightgbm.pkl')\n",
    "scaler = joblib.load('shark_model_scaler.pkl')\n",
    "print(\"Model and scaler loaded successfully.\")\n",
    "\n",
    "# 2. Create a Grid for the North Atlantic\n",
    "print(\"Creating prediction grid...\")\n",
    "min_lon, max_lon = -80, -60\n",
    "min_lat, max_lat = 30, 50\n",
    "grid_resolution = 0.5 # Degrees\n",
    "\n",
    "lons = np.arange(min_lon, max_lon, grid_resolution)\n",
    "lats = np.arange(min_lat, max_lat, grid_resolution)\n",
    "lon_grid, lat_grid = np.meshgrid(lons, lats)\n",
    "\n",
    "grid_df = pd.DataFrame({\n",
    "    'lon': lon_grid.flatten(),\n",
    "    'lat': lat_grid.flatten()\n",
    "})\n",
    "\n",
    "# 3. Engineer the SAME features for the grid that the model was trained on\n",
    "print(\"Engineering features for the grid...\")\n",
    "month = 8  # Predict for August\n",
    "hour = 22  # Predict for 10 PM\n",
    "\n",
    "# Time features\n",
    "grid_df['hour_sin'] = np.sin(2 * np.pi * hour/24.0)\n",
    "grid_df['hour_cos'] = np.cos(2 * np.pi * hour/24.0)\n",
    "grid_df['month_sin'] = np.sin(2 * np.pi * month/12.0)\n",
    "grid_df['month_cos'] = np.cos(2 * np.pi * month/12.0)\n",
    "\n",
    "# --- ADDED FIX: Re-create the original 'hour' and 'month' columns ---\n",
    "# The saved scaler expects to see these columns, so we add them here.\n",
    "grid_df['hour'] = hour\n",
    "grid_df['month'] = month\n",
    "\n",
    "# Add all other feature columns with a neutral value (like 0 or the median)\n",
    "placeholder_features = [\n",
    "    'speed_avg_roll', 'speed_std_roll', 'angle_avg_roll', 'angle_std_roll',\n",
    "    'speed_percentile', 'is_slow', 'speed_change', 'high_turn_angle',\n",
    "    'angle_consistency', 'speed_angle_ratio', 'movement_efficiency',\n",
    "    'turning_intensity', 'lat_rounded', 'lon_rounded', 'distance_from_center',\n",
    "    'dawn_dusk', 'night', 'speed_z_score', 'angle_z_score'\n",
    "]\n",
    "for feat in placeholder_features:\n",
    "    grid_df[feat] = 0.0\n",
    "\n",
    "# Recreate location-based features with actual values\n",
    "grid_df['lat_rounded'] = np.round(grid_df['lat'], 2)\n",
    "grid_df['lon_rounded'] = np.round(grid_df['lon'], 2)\n",
    "# Approximate center of the data to calculate distance\n",
    "lat_mean_approx = 40.0\n",
    "lon_mean_approx = -70.0\n",
    "grid_df['distance_from_center'] = np.sqrt((grid_df['lat'] - lat_mean_approx)**2 + (grid_df['lon'] - lon_mean_approx)**2)\n",
    "\n",
    "# Get the feature names IN THE CORRECT ORDER from the scaler object\n",
    "try:\n",
    "    # For newer scikit-learn versions\n",
    "    X_train_columns = scaler.get_feature_names_out()\n",
    "except AttributeError:\n",
    "    # For older scikit-learn versions\n",
    "    X_train_columns = scaler.feature_names_in_\n",
    "\n",
    "# Ensure the column order is exactly the same as the training data\n",
    "grid_df = grid_df[X_train_columns]\n",
    "\n",
    "# 4. Scale the Grid Features\n",
    "print(\"Scaling grid features...\")\n",
    "grid_scaled = scaler.transform(grid_df)\n",
    "\n",
    "# 5. Make Predictions\n",
    "print(\"Predicting foraging probability on the grid...\")\n",
    "probabilities = model.predict_proba(grid_scaled)[:, 1]\n",
    "grid_df['probability'] = probabilities\n",
    "print(\"Prediction complete.\")\n",
    "\n",
    "# 6. Export to GeoJSON\n",
    "print(\"Exporting results to hotspots.geojson...\")\n",
    "features = []\n",
    "for i, row in grid_df.iterrows():\n",
    "    if row['probability'] > 0.6: # You can adjust this threshold\n",
    "        point = geojson.Point((row['lon'], row['lat']))\n",
    "        feature = geojson.Feature(geometry=point, properties={'probability': round(float(row['probability']), 4)})\n",
    "        features.append(feature)\n",
    "\n",
    "feature_collection = geojson.FeatureCollection(features)\n",
    "with open('hotspots.geojson', 'w') as f:\n",
    "    geojson.dump(feature_collection, f)\n",
    "\n",
    "print(\"\\n✅ Phase 3 Complete! Your final, high-performance 'hotspots.geojson' is ready.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
